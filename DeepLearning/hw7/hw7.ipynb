{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0beee282-5694-4c09-9f63-ee0486614aa1",
   "metadata": {},
   "source": [
    "# Ex7 - Deep Learning Questions - Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d5194-02c1-46f3-a97a-cd8361da7e32",
   "metadata": {},
   "source": [
    "## 1. Explain each of these terms in a sentence or two:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1690b73-d808-4ebd-a5cd-629f490074bd",
   "metadata": {},
   "source": [
    "### 1. Cross entropy\n",
    "Cross-entropy measures the performance of a classification model based on the probability and error, where the more likely (or the bigger the probability) of something is, the lower the cross-entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770bbdc3-ef4e-45b3-9d51-2a7f7dd3cd11",
   "metadata": {},
   "source": [
    "### 2. Residual connections\n",
    "A residual connection connects the output of one earlier convolutional layer to the input of another future convolutional layer several layers later. \n",
    "Several intermediate convolutional layers are skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d44ed3-d965-40b2-a3c6-8d622f40fe5a",
   "metadata": {},
   "source": [
    "### 3. Adam optimizer\n",
    "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50300d1-9b07-48f2-89ed-ad29251de404",
   "metadata": {},
   "source": [
    "### 4. Cyclic learning rate\n",
    "Cyclic learning rate is a technique to set and change and tweak LR during training.\n",
    "This methodology aims to train neural network with a LR that changes in a cyclical way for each batch, instead of a non-cyclic LR that is either constant or changes on every epoch. The learning rate schedule varies between two bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220bee9-66d5-46de-8800-9a517f69507f",
   "metadata": {},
   "source": [
    "### 5. Dropout\n",
    "Dropout is a method where randomly selected neurons are dropped during training. They are “dropped-out” arbitrarily. This infers that their contribution to the activation of downstream neurons is transiently evacuated on the forward pass and any weight refreshes are not applied to the neuron on the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f1b50-2eab-4b2e-97be-95461eece3a1",
   "metadata": {},
   "source": [
    "### 6. Bottleneck layer\n",
    "A bottleneck layer is a layer that contains few nodes compared to the previous layers. It can be used to obtain a representation of the input with reduced dimensionality. An example of this is the use of autoencoders with bottleneck layers for nonlinear dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290dbca-dd89-42bf-96e8-0a3f50df9469",
   "metadata": {},
   "source": [
    "### 7. 1x1 convolution\n",
    "1x1 convolution can be seen as an operation where a 1 x 1 x K sized filter is applied over the input and then weighted to generate F activation maps.<br> F > K results in an increase in the filter dimension whereas F < K would cause an output with reduced filter dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25093234-78fe-4928-8343-e776c5fd412e",
   "metadata": {},
   "source": [
    "### 8. DenseNet\n",
    "A DenseNet is a type of convolutional neural network that utilises dense connections between layers, through Dense Blocks, where we connect all layers (with matching feature-map sizes) directly with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176bf53-3736-4027-90ef-ce995ac1a498",
   "metadata": {},
   "source": [
    "## 2. \n",
    "Explain the pros and cons of using small and large batch sizes.<br><br>\n",
    "**Answer:**<br>\n",
    "- higher batch sizes leads to lower asymptotic test accuracy\n",
    "- we can recover the lost test accuracy from a larger batch size by increasing the learning rate\n",
    "- starting with a large batch size doesn’t “get the model stuck” in some neighbourhood of bad local optimums. The model can switch to a lower batch size or higher learning rate anytime to achieve better test accuracy\n",
    "- too large batch size will lead to poor generalization\n",
    "- small batches go through the system more quickly and with less variability, which fosters faster learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f09028-212d-4fa0-a786-4ed5d7c644de",
   "metadata": {},
   "source": [
    "## 3. \n",
    "How many 3x3 filters are needed to replace a 7x7 kernel? Compare the number of parameters in each option.<br>\n",
    "**Answer:**<br>\n",
    "Three 3x3 filters sequentially can replace 7x7 filter.\n",
    "To apply two 3x3 kernels, we need (3x3 + 3x3 + 3x3) = 27 weights. But, using one 7x7 kernel, we will need 49 weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41b5ce-0673-4932-82b0-fde1aa3269a8",
   "metadata": {},
   "source": [
    "## 4. \n",
    "You are training a neural network for classifying images on a custom dataset and it doesn't seem to learn anything. Describe your approach to solving the issue.<br>\n",
    "**Answer:**\n",
    "\n",
    "- Look for Variables that are created but never used (usually because of copy-paste errors)\n",
    "- Look for Expressions for gradient updates are incorrect\n",
    "- Look for Weight updates that are not applied\n",
    "- Look for Loss functions that are not measured on the correct scale (for example, cross-entropy loss can be expressed in terms of probability or logits)\n",
    "- Look for The loss that is not appropriate for the task (for example, using categorical cross-entropy loss for a regression task).\n",
    "- Look for Dropout that is used during testing, instead of only being used for training.\n",
    "- Make sure you're minimizing the loss function L(x), instead of minimizing −L(x).\n",
    "- Make sure your loss is computed correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8bb9d-370e-4eac-96d9-1945d50fa84c",
   "metadata": {},
   "source": [
    "## 5. \n",
    "Mention the problems imbalanced datasets can cause to Deep Learning problems, and suggest a few ways to avoid them.<br>\n",
    "**Answer:** <br>\n",
    "The main problem with imbalanced dataset prediction is that we fail to predict accurately minority class. <br>\n",
    "**Ways to avoid problems:**\n",
    "- Changing the Performance Metric\n",
    "- Resampling the Dataset by adding copies of instances from the under-represented (over-sampling) or deleting delete instances from the over-represented class (under-sampling)\n",
    "- Generatinh Synthetic Samples to randomly sample the attributes from instances in the minority class.\n",
    "- Reworking the problem itself by tackling an imbalanced classes problem: the classifier and the decision rule have to be set with respect to a well chosen goal that can be, for example, minimising a cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8c2c4-c24f-4454-860c-8fee308c2fbf",
   "metadata": {},
   "source": [
    "## 6. \n",
    "Given two networks: SRCNN (https://arxiv.org/pdf/1501.00092.pdf) and Unet (https://arxiv.org/pdf/1505.04597.pdf) . What is the receptive field of a pixel in each network? You should consider one pixel (let’s say the center pixel of the output) and go back to see what neighbors at the input image influence this pixel.<br><br>\n",
    "**Answer:**<br><br>\n",
    "Algorithm for calculating receptive field size:<br>\n",
    "r=1<br>\n",
    "S=1<br>\n",
    "for l = 0 to L do<br>\n",
    ">  for i = 0 to l do<br>\n",
    ">>    S=S*si<br>\n",
    ">>    r=r+(kl-1)*S<br><br>\n",
    "\n",
    "\n",
    "**SRCNN:**<br>\n",
    "\n",
    "```python\n",
    "stride1 = 14 \n",
    "stride2 = 1 \n",
    "stride3 = 1\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=9, padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=5 // 2)\n",
    "        self.conv3 = nn.Conv2d(32, num_channels, kernel_size=5, padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "```\n",
    "\n",
    "r1 = 1 + (9-1) * 14 = 113 <br>\n",
    "r2 = 113 + (5-1) * 14  = 169 <br>\n",
    "r3 = 169 + (5-1) * 14 = 225 <br>\n",
    "\n",
    "Hence,  SRCNN's receptive field size is: 225 <br>\n",
    "\n",
    "**U-NET:**<br>\n",
    "```python\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "```\n",
    "<br>\n",
    "We have a total of 23 layers in whcih there are:<br> \n",
    "4 max pooling (2x2) layers with stride of 2 <br>\n",
    "18 conv layers (3x3) with stride of 1 <br>\n",
    "1 conv layers (1x1) with stride of 1 <br>\n",
    "receptive field size = <br>\n",
    "1+ (3-1) * 1 + <br>\n",
    "1+ (3-1) * 1 +<br>\n",
    "1+ (3-1) * 1 +<br>\n",
    "1+ (3-1) * 1 +<br>\n",
    "1+ (2-1) * 2 +<br>\n",
    "1+ (3-1) * 2 +<br>\n",
    "1+ (3-1) * 2 +<br>\n",
    "1+ (2-1) * 4 +<br>\n",
    "1+ (3-1) * 4 +<br>\n",
    "1+ (3-1) * 4 +<br>\n",
    "1+ (2-1) * 8 +<br>\n",
    "1+ (3-1) * 8 +<br>\n",
    "1+ (3-1) * 8 +<br>\n",
    "1+ (2-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (3-1) * 16 +<br>\n",
    "1+ (1-1) * 16 =<br>\n",
    "=373  <br>\n",
    "Hence,  U-Net's receptive field size  is: 373 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c3f55-e3c6-4622-ba76-f1cc197a5d4e",
   "metadata": {},
   "source": [
    "## 7. \n",
    "Given a standard CNN consists of convolutional layers and then fully-connected layers. Explain what layer in CNN can reach a lot of parameters? How can we avoid it?\n",
    "\n",
    "**Answer:**<br>\n",
    "FC layers increase the number of parameters so after each such layer we get more parameters.\n",
    "We can avoid getting lots of parameters by increasing number of convolutional layers or decreasing the number of FC layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f9fcb-eee0-4145-aadf-4939d83de661",
   "metadata": {},
   "source": [
    "## 8. \n",
    "What is the result of convolving an image X with a filter h = [-1 -1 -1; 0 0 0; 1 1 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddef3edc-8e81-457a-8f13-e3ce99e13779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x * k1 =\n",
      "[[ 7  4  1 -1 -2]\n",
      " [-3  5  9 12 10]\n",
      " [-5 -3 -5 -4 -4]\n",
      " [-2 -1 -2 -4 -6]\n",
      " [-7  3 11 13 10]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage as ndi\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) \n",
    "\n",
    "x = np.array([[-1, -3, -4,  0, -1],\n",
    "               [ 2, -2, -4,  0, -2],\n",
    "               [-3, -2,  2,  2,  3],\n",
    "               [ 0, -3, -4, -4, -2],\n",
    "               [-4, -2,  2,  0,  1]])\n",
    "\n",
    "k1 = np.array([[-1, -1, -1], [0, 0, 0], [1,1,1]])\n",
    "\n",
    "\n",
    "\n",
    "print('x * k1 =')\n",
    "print(ndi.correlate(x, k1),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b42a4-b17c-449f-bc12-5075d22387f7",
   "metadata": {},
   "source": [
    "## 9. \n",
    "(a) What if all the weights are initialized with the same value?<br><br>\n",
    "**Answer:**<br>\n",
    "If all weights are the same, all units in hidden layer will be the same too. <br>\n",
    "If the gradients are equal then weights are going to be updated by the same amount. The weights attached to the same neuron, continue to remain the same throughout the training. It makes the hidden units symmetric and this problem is known as the symmetry problem - the network can't learn<br><br>\n",
    "(b) What happens if we set all the biases to be zero (ignoring the biases)?<br><br>\n",
    "**Answer:**<br>\n",
    "Setting biases to 0 will not create any problems as non-zero weights take care of breaking the symmetry and even if bias is 0, the values in every neuron will still be different (as long as different weights were used upon initialization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709c9e8-ea17-469d-a2f4-aa39ae4006b2",
   "metadata": {},
   "source": [
    "## 10. \n",
    "Write down two NN models (it can also be convolutional networks) that have (more or less) the same number of parameters, but with different power of computational. Explain your answer.\n",
    "\n",
    "**Answer:**<br>\n",
    "\n",
    "params = weights + biases = i × (f×f) × o + o <br>\n",
    "\n",
    "**CNN1:** Greyscale image 10x10 with 2×2 filter, output 3 channels <br>\n",
    "i = 1 (greyscale has only 1 channel) <br>\n",
    "f = 2 <br>\n",
    "o = 3 <br>\n",
    "params = = 1 × (2×2) × 3 + 3 = 15<br>\n",
    "calculations =  3 × (2×2) × 1 × 2 × 10×10 = 2400 <br>\n",
    "\n",
    "**CNN2:** RGB image 20x20 with 2×2 filter, output of 1 channel <br>\n",
    "i = 3 (RGB image has 3 channels)<br>\n",
    "f = 2<br>\n",
    "o = 1<br>\n",
    "params = 3 × (2×2) × 1 + 1 = 13 <br>\n",
    "calculations =  1 × (2×2) × 3 × 2 × 20×20 = 9600 <br>\n",
    "\n",
    "We can see the despite the fact that number of parameters is almost the same (15 vs 13) the computational power (number of calculations) differs significantly due to the difference of the input image size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ed56e-0bc1-4265-978d-286e066a1b56",
   "metadata": {},
   "source": [
    "## 11.\n",
    "You moved into a new apartment and you would like to make your front door smarter. Write an algorithm that alerts every time there is someone outside your door who is not a part of your family (you decide who is considered to be family).\n",
    "\n",
    "**Answer:**<br>\n",
    "We need to train our model on greyscale images of our family members and some other strangers. We'll label family members with 1 and strangers with 0.<br>\n",
    "We'll init our weight vector with zeros. <br>\n",
    "We'll start iterating over our training data and for each image smaple we'll  multiply the weights by the inputs.\n",
    "We set learning rate and multiply the results by it before summing them up. That's how we get the dot product. <br>\n",
    "Next we would compare the dot product with the predefined threshold to calculate a new estimate, update the weights, and then keep going. If our data is linearly separable, the Perceptron will converge. <br>\n",
    "After we have completed training the model we can validate it by sending him new greyscale images both for family members and strangers.<br>\n",
    "The output will be 1 for family members and 0 for strangers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843c35d-0933-4e30-9c24-55816571cbef",
   "metadata": {},
   "source": [
    "## 12. \n",
    "These days, most of the parking lots have a system that recognizes the license plate number of an entering car. This helps to automatically open the gate in case that the driver paid before arriving at the exit gate. For this purpose, two cameras are needed - one at the entrance and one at the exit. Both capture the license plate number and translate it into a series of numbers.\n",
    "\n",
    "Write an algorithm that for a given image containing a car with a license plate number,\n",
    "recognizes all the numbers in this plate. Pay attention that the angle and the location of the\n",
    "license plate can vary between images.\n",
    "\n",
    "For simplicity: all the license plates have the same size (in the real world, not in the image), have 7 digits and have the same font. The plate is yellow with black digits. Some pictures are attached.\n",
    "\n",
    "Moreover, no trucks or motorcycles can enter the parking lot. If you have more assumptions, please write them down.\n",
    "\n",
    "**Answer:**<br>\n",
    "1. Pre-processing:<br>\n",
    "      1.1 Convert the gray scale image into binary image using Otsu’s algorithm by\n",
    "calculating thresholding. <br>\n",
    "      1.2 Remove all the objects containingfewer than 30 pixel. Median filter to remove the noise.<br>\n",
    "      1.3 Calculate connected components of an image byscanning the image, pixel by pixel (from top to bottom and leftto right)in order to identify connected pixel regions. <br>\n",
    "      1.4 Search for connected components in the image, eachconnected component will be assigned a special label in order to distinguish between different connected components in the image.<br>\n",
    "      1.5 Resize each character from the previous step to thestandard height and width in order to be used in therecognition process.<br>\n",
    "      1.6 Measure properties of image regions by ploting bounding box to get the separate character and numbers forrecognition process.<br>\n",
    "2. Number plate localizarion - a number of algorithms are suggested for number plate localization such as: multiple interlacing algorithm, Fourier domain filtering, and colour image processing.  <br>\n",
    "      2.1 A statistical Median filter is used to remove salt and peppernoise from the image inn gray scale before binarizing. Wehave used a 3 *3 masking sub window for this purpose.  <br>\n",
    "      2.2 Connected Components - Connected components labeling scans an image andgroups its pixels into components based on pixel connectivity, i.e. all pixels in a connected component share similar pixel intensityvalues and are in some way connected with each other. Onceall groups have been determined, each pixel is labeled with agray level or a color (color labeling) according to the component it was assigned to.<br>\n",
    "3. Charachter segmentation -   <br>\n",
    "      3.1 Working with bounding box - the minimum or the smallest bounding box for any point set in N dimention is the box with smallest measure within whichall point lies. In the other words it has the minimum heightand width that cover all the pixels present in a particularconnected component or region.<br>\n",
    "      3.2 Selecting the best Bounding Box by <br>\n",
    "      * Contrast present in the bounding box\n",
    "      * Aspect Ratio\n",
    "      * Width of the license plate\n",
    "      3.3 Cropping the Bounding Box - after identifying the best possible bounding box candidate forthe license plate the coordinates of the bounding box are notedand the box is cropped from the image and sent to charactersegmentation module for further processing\n",
    "4. Charachter recognition - the image obtained after segmentation is Grayscale.Follow the preprocessing steps used for the training of thecharacters. Calculate the score for each of the characters: We calculate the matching score of the segmented characterfrom the templates of the character stored by the following algorithm. We compare the pixel values of thematrix of segmented character and the template matrix, and for every match we add 1 to the matching score and for everymiss-match we decrement 1. This is done for all 225 pixels. The match score is generated for every template and the one which gives the highest score is taken to be the recognized character.\n",
    "5. We got the number :)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
