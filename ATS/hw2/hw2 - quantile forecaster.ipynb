{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17852b60-5cff-4085-9444-8123c8465469",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388643fd-9710-4118-83b5-fa7e52b39353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "# from datasets.ElectricityLoadDataset import ElectricityLoadDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "# from external_links.utills import DATA_DIR, download_dataset\n",
    "import pathlib\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93cbbf-e6b6-4a11-b3c6-201c40c9d2d4",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e811dc32-a170-4144-ada3-0b0361742256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset():\n",
    "    url_str = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip'\n",
    "    zip_out = DATA_DIR/\"LD2011_2014.txt.zip\"\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "    file_content = requests.get(url_str).content\n",
    "    with open(zip_out, 'wb') as out_file:\n",
    "        out_file.write(file_content)\n",
    "    with ZipFile(zip_out, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a54b25-0367-42c5-a693-50ff880c2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityLoadDataset(Dataset):\n",
    "    \"\"\"Sample data from electricity load dataset (per household, resampled to one hour).\"\"\"\n",
    "\n",
    "    def __init__(self, df, samples, hist_num=168, fct_num=24):\n",
    "        self.hist_num = hist_num\n",
    "        self.fct_num = fct_num\n",
    "        self.hist_len = pd.Timedelta(hours=hist_num)\n",
    "        self.fct_len = pd.Timedelta(hours=fct_num)\n",
    "        self.offset = pd.Timedelta(hours=1)\n",
    "        self.samples = samples\n",
    "\n",
    "        self.max_ts = df.index.max() - self.hist_len - self.fct_len + self.offset\n",
    "        self.raw_data = df.copy()\n",
    "\n",
    "        assert samples <= self.raw_data[:self.max_ts].shape[0]\n",
    "\n",
    "        self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Sample individual series as needed.\"\"\"\n",
    "\n",
    "        # Calculate actual start for each household\n",
    "        self.clean_start_ts = (self.raw_data != 0).idxmax()\n",
    "\n",
    "        households = []\n",
    "\n",
    "        for household in self.raw_data.columns:\n",
    "            hh_start = self.clean_start_ts[household]\n",
    "            hh_nsamples = min(self.samples, self.raw_data.loc[hh_start:self.max_ts].shape[0])\n",
    "\n",
    "            hh_samples = (self.raw_data\n",
    "                          .loc[hh_start:self.max_ts]\n",
    "                          .index\n",
    "                          .to_series()\n",
    "                          .sample(hh_nsamples, replace=False)\n",
    "                          .index)\n",
    "            households.extend([(household, start_ts) for start_ts in hh_samples])\n",
    "\n",
    "        self.samples = pd.DataFrame(households, columns=(\"household\", \"start_ts\"))\n",
    "\n",
    "        # Adding calendar features\n",
    "        self.raw_data[\"yearly_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.dayofyear / 366)\n",
    "        self.raw_data[\"weekly_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.dayofweek / 7)\n",
    "        self.raw_data[\"daily_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.hour / 24)\n",
    "        self.calendar_features = [\"yearly_cycle\", \"weekly_cycle\", \"daily_cycle\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        household, start_ts = self.samples.iloc[idx]\n",
    "\n",
    "        hs, he = start_ts, start_ts + self.hist_len - self.offset\n",
    "        fs, fe = he + self.offset, he + self.fct_len\n",
    "\n",
    "        hist_data = self.raw_data.loc[hs:, [household] + self.calendar_features].iloc[:self.hist_num]\n",
    "        fct_data = self.raw_data.loc[fs:, [household] + self.calendar_features].iloc[:self.fct_num]\n",
    "\n",
    "        return (torch.Tensor(hist_data.values),\n",
    "                torch.Tensor(fct_data.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d410587-254a-4b23-88eb-90bb0343d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class ElectricityLoadModel(pl.LightningModule):\n",
    "    \"\"\"Encoder network for encoder-decoder forecast model.\"\"\"\n",
    "\n",
    "    def __init__(self, hist_len=168, fct_len=24, input_size=4, num_layers=1, hidden_units=8, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hist_len = hist_len\n",
    "        self.fct_len = fct_len\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_units = hidden_units\n",
    "        self.lr = lr\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,\n",
    "                            hidden_size=self.hidden_units,\n",
    "                            num_layers=self.num_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.mu = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "        self.sigma_raw = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "        self.sigma = nn.Softplus()\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        output, (hh, cc) = self.lstm(x)\n",
    "        mu = self.mu(output)\n",
    "        sigma = self.sigma(self.sigma_raw(output))\n",
    "        return output, mu, sigma, hh, cc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        combined_input = torch.cat(batch, dim=1)\n",
    "\n",
    "        # Pushing through the network\n",
    "        out, mu, sigma, hh, cc = self(combined_input[:, :-1, :])\n",
    "\n",
    "        return self.loss(mu, sigma, combined_input[:, 1:, [0]])\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        combined_input = torch.cat(batch, dim=1)\n",
    "\n",
    "        # Pushing through the network\n",
    "        out, mu, sigma, hh, cc = self(combined_input[:, :-1, :])\n",
    "\n",
    "        loss = self.loss(mu, sigma, combined_input[:, 1:, [0]])\n",
    "        self.log('val_logprob', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def sample(self, x, samples):\n",
    "        # Handle single stream or multiple streams\n",
    "        x = x.view(-1, self.hist_len, 4)\n",
    "\n",
    "        # Initial pass - `mu(T+1)` and `sigma(T+1)` are ready\n",
    "        out, mu, sigma, hh_initial, cc_initial = self(x)\n",
    "\n",
    "        # Sample from the distribution\n",
    "        gaussian = torch.distributions.normal.Normal(mu[:, -1, -1], sigma[:, -1, -1])\n",
    "        initial_sample = gaussian.sample((samples,))\n",
    "\n",
    "        # Getting calendar features\n",
    "        calendar_features = x[:, -self.fct_len:, 1:]\n",
    "\n",
    "        all_samples = []\n",
    "\n",
    "        # Iterating over samples\n",
    "        for sample in range(samples):\n",
    "            current_sample = initial_sample[sample]\n",
    "\n",
    "            # We want output to be `(fct_len, batch_size, samples)`\n",
    "            local_samples = [current_sample.view(1, -1, 1)]\n",
    "\n",
    "            # Initialize hidden and cell state to encoder output\n",
    "            hh, cc = hh_initial, cc_initial\n",
    "\n",
    "            # Iterating over time steps\n",
    "            for step in range(self.fct_len - 1):\n",
    "                # Input tensor for this step\n",
    "                step_in = torch.cat([current_sample.view(-1, 1, 1),\n",
    "                                     calendar_features[:, [step], :]], dim=-1)\n",
    "\n",
    "                step_out, mu, sigma, hh, cc = self(step_in, (hh, cc))\n",
    "\n",
    "                # Sampling the next step value\n",
    "                gaussian = torch.distributions.normal.Normal(mu[:, -1, -1], sigma[:, -1, -1])\n",
    "                current_sample = gaussian.sample((1,))\n",
    "\n",
    "                # Storing the samples for this time step\n",
    "                local_samples.append(current_sample.unsqueeze(-1))\n",
    "\n",
    "            # Storing all samples for this sample\n",
    "            all_samples.append(torch.cat(local_samples, dim=0))\n",
    "        return torch.cat(all_samples, -1)\n",
    "\n",
    "    def loss(self, mu, sigma, y):\n",
    "        # Distribution with generated `mu` and `sigma`\n",
    "        gaussian = torch.distributions.normal.Normal(mu, sigma)\n",
    "\n",
    "        # Log-likelihood\n",
    "        L = gaussian.log_prob(y)\n",
    "\n",
    "        return -torch.mean(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf145467-ebc0-40e7-8a2e-e41d94a81a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityLoadDataModule(pl.LightningDataModule):\n",
    "    \"\"\"DataModule for electricity data.\"\"\"\n",
    "\n",
    "    def __init__(self, df,\n",
    "                 train=0.7,\n",
    "                 val=0.2,\n",
    "                 test=0.1,\n",
    "                 samples=100,\n",
    "                 batch_size=64,\n",
    "                 workers=3):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        assert train + val + test <= 1\n",
    "\n",
    "        self.raw_data = df\n",
    "        self.train_size = int(train * df.shape[1])\n",
    "        self.val_size = int(val * df.shape[1])\n",
    "        self.test_size = df.shape[1] - self.train_size - self.val_size\n",
    "\n",
    "        self.samples = samples\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "        self.split()\n",
    "\n",
    "    def split(self):\n",
    "        hh_rand = (self.raw_data\n",
    "                   .columns\n",
    "                   .to_series()\n",
    "                   .sample(self.raw_data.shape[1],\n",
    "                           replace=False))\n",
    "\n",
    "        self.train_hh = hh_rand.iloc[:self.train_size].index\n",
    "        self.val_hh = hh_rand.iloc[self.train_size:(self.val_size + self.train_size)].index\n",
    "        self.test_hh = hh_rand.iloc[-self.test_size:].index\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_df = self.raw_data[self.train_hh]\n",
    "            val_df = self.raw_data[self.val_hh]\n",
    "\n",
    "            self.train_ds = ElectricityLoadDataset(train_df,\n",
    "                                                   samples=self.samples)\n",
    "            self.val_ds = ElectricityLoadDataset(val_df,\n",
    "                                                 samples=self.samples)\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            test_df = self.raw_data[self.test_hh]\n",
    "            self.test_ds = ElectricityLoadDataset(test_df,\n",
    "                                                  samples=self.samples)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, num_workers=self.workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602a107b-84e6-45b9-bc37-0990008e4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pyplot_style():\n",
    "    plt.style.use(\"bmh\")\n",
    "    plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "\n",
    "# eldata = pd.read_parquet(DATA_DIR.joinpath(\"LD2011_2014.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a7a4e6-f014-4aaf-8796-903576b1b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    data_path = os.path.join(DATA_DIR, \"LD2011_2014.txt\")\n",
    "\n",
    "    if not os.path.isfile(data_path):\n",
    "        download_dataset()\n",
    "\n",
    "    assert os.path.isdir(DATA_DIR)\n",
    "    assert os.path.isfile(data_path)\n",
    "\n",
    "    eldata = pd.read_csv(data_path,\n",
    "                         parse_dates=[0],\n",
    "                         delimiter=\";\",\n",
    "                         decimal=\",\")\n",
    "    eldata.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "    #\n",
    "    # print(eldata.head())\n",
    "    #\n",
    "    eldata = eldata.resample(\"1H\", on=\"timestamp\").mean()\n",
    "    #\n",
    "    # (eldata != 0).mean().plot()\n",
    "    # plt.ylabel(\"non-zero %\")\n",
    "    #\n",
    "    eldata[eldata != 0].median().sort_values(ascending=False).plot(rot=90)\n",
    "    # plt.yscale(\"log\")\n",
    "    #\n",
    "    # plt.ylabel(\"magnitude\")\n",
    "    #\n",
    "    # dataset = ElectricityLoadDataset(eldata, 100)\n",
    "    #\n",
    "    # hist, fct = dataset[4]\n",
    "    #\n",
    "    # print(f\"hist.shape: {hist.shape}\")\n",
    "    # print(f\"fct.shape: {fct.shape}\")\n",
    "    #\n",
    "    # dataset.samples.groupby(\"household\").size().unique()\n",
    "    #\n",
    "    # dm = ElectricityLoadDataModule(eldata)\n",
    "    # dm.setup()\n",
    "    #\n",
    "    # assert dm.train_hh.intersection(dm.val_hh).empty\n",
    "    # assert dm.train_hh.intersection(dm.test_hh).empty\n",
    "    # assert dm.train_hh.size + dm.val_hh.size + dm.test_hh.size == 370\n",
    "    #\n",
    "    # x, y = next(iter(dm.train_dataloader()))\n",
    "    #\n",
    "    # print(f\"x.shape: {x.shape}, y.shape: {y.shape}\")\n",
    "    #\n",
    "    scaled_data = eldata / eldata[eldata != 0].mean() - 1\n",
    "\n",
    "    dm = ElectricityLoadDataModule(scaled_data, batch_size=128)\n",
    "    model = ElectricityLoadModel(lr=1e-3, hidden_units=64, num_layers=1)\n",
    "    trainer = pl.Trainer(max_epochs=5, progress_bar_refresh_rate=1, gpus=1)\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "    # Example forecasts\n",
    "    dm.setup(stage=\"test\")\n",
    "\n",
    "    batch = next(iter(dm.test_dataloader()))\n",
    "\n",
    "    X, y = batch\n",
    "\n",
    "    result = model.sample(X, 100)\n",
    "\n",
    "    print(f\"result.shape: {result.shape}\")\n",
    "\n",
    "    plt.plot(result.mean(dim=-1).numpy()[:, 8])\n",
    "    plt.plot(y[8, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46dc34-c0bd-4a1e-a9f9-c328d9c3d6d7",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e21775-484a-4b52-a0bd-def19c279880",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = pathlib.Path(\"..\")\n",
    "DATA_DIR = pathlib.Path(\"../data\")\n",
    "set_pyplot_style()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb981d-3a52-4b10-be58-62f9f5bf9e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
