{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cython\n",
    "\n",
    "Being a C program itself, Python has a powerful and well developed C API, which allows writing C extensions. However, Python C API is considered an advanced tool and native development of C extensions is slow and error-prone.\n",
    "\n",
    "Cython is a static compiler for Python. It allows writing Python C extensions with less effort compared to traditional Python C API way.\n",
    "\n",
    "General Cython pipeline looks as the following:\n",
    "\n",
    "- you develop some code in pure Python and **profile** it with `line_profiler` (or alike) to catch hotspots,\n",
    "- you decide on the strategy to optimize your code. Typically, this would involve transforming PYthon code to Cython code by **adding type information**, and using **typed memoryviews** instead of NumPy arrays,\n",
    "- then you generate C extension module from Cython code and test its performance. If it ok - end of the story, if it's not, you continue.\n",
    "\n",
    "Cython knows a lot about NumPy arrays and allows interfacing with them easily. Cython code itself looks a lot like a mixture of C and Python. Cython compiler generates C extensions code from Cython code and compiles it with system compiler as a loadable C extension.\n",
    "\n",
    "In this material, we will use `Cython` extension for Jupyter to avoid writing modules and compile them with `setup.py` (although that's also simple enough). This may not work on Windows very well, as Cython requires C compiler to generate extension modules from C code, and it is sometimes tricky to setup correctly on Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "We will implement matrix multiplication using Cython. We'll start with naive and straightforward implementation, measure it's performance and compare it with `np.dot` performance. Then, we will try to improve it using smarter memory access pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:40.379513Z",
     "start_time": "2019-11-25T21:13:39.777822Z"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:40.385444Z",
     "start_time": "2019-11-25T21:13:40.381986Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, NumPy uses system linear algebra libraries (OpenBLAS in this case, but it may Intel MKL or something else) and it is usually much slower without them. Those libraries contain highly optimized and well-tested code, which very often leverages available CPU features (SSE, AVX, etc.) to make computation as efficient as possible. Note, that your machine may show different libraries, and it's only important that you see **something** and not pure NumPy implementation.\n",
    "\n",
    "In real world you will often optimize custom algorithms with Cython, not simple linear algebra operations, so we won't compete with decades of linear algebra routines development. Instead, we want to know a) what we're comparing against, b) what we can achieve with Cython compared to naive Python implementations.\n",
    "\n",
    "We need some tools to measure performance, so that we can plot running time to see the pattern. Although there are many different ways to do this, we will use `%timeit`. Note, that we can catch output of `%timeit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:40.459647Z",
     "start_time": "2019-11-25T21:13:40.392100Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.random.randn(1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:42.448804Z",
     "start_time": "2019-11-25T21:13:40.465985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns TimeitResult object\n",
    "s = %timeit -n 10 -r 3 -o np.dot(arr, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:42.465281Z",
     "start_time": "2019-11-25T21:13:42.454191Z"
    }
   },
   "outputs": [],
   "source": [
    "s.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem with matrix multiplication\n",
    "\n",
    "Product of matrices $A$ and $B$ is a matrix $C$:\n",
    "\n",
    "$$C_{ik} = A_{ij}B_{jk}.$$\n",
    "\n",
    "You can immediately spot the problem here. If both matrices are in row-major order, $B$ is accessed in wrong direction: you hop through array rows, which leads to a lot of cache misses.\n",
    "\n",
    "Anyway, it's interesting to understand, how naive implementation performs. Let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typed memoryviews\n",
    "\n",
    "To represent homogeneous buffers of data (which NumPy arrays are) in Cython, we have what is called [_typed memoryview_](https://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html). Typed memoryview is a handle to underlying buffer of Python object, if there's a buffer, of course (`array` from standard library will work as well). Consult typed memoryviews docs to understand the declaration structure.\n",
    "\n",
    "We first import `Cython` extension. `Cython` extension does all the job for us: generates C extension module, compiles it and loads the function as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:43.372415Z",
     "start_time": "2019-11-25T21:13:42.469805Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see some hints from Cython we will use **annotations** (`--annotate` key). With this option, Cython will mark all the Python interaction in yellow. Generally, using functions from Python interpreter itself should be avoided, as they go throught Python stack and are hence slow. You can click on `+` in the output to see the actual C code generated by Cython.\n",
    "\n",
    "`%cython` magic will do all the underlying work (generating C extension, compiling it and loading it) for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:43.392116Z",
     "start_time": "2019-11-25T21:13:43.375717Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "# In this function we have memoryview of buffer of doubles as an argument\n",
    "def sum_arr(double[:] a):\n",
    "    \"\"\"Sum elements of `a`.\"\"\"\n",
    "\n",
    "    result = 0.\n",
    "\n",
    "    # Note, that typed memoryviews know about shape\n",
    "    for i in range(a.shape[0]):\n",
    "        result += a[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that computation is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:43.450399Z",
     "start_time": "2019-11-25T21:13:43.397285Z"
    }
   },
   "outputs": [],
   "source": [
    "# BTW, why do we need to flatten our array?\n",
    "arr_f = arr.flatten()\n",
    "sum_arr(arr_f), arr.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And measure how it compares to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:52.497439Z",
     "start_time": "2019-11-25T21:13:43.453793Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 sum_arr(arr_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:52.770994Z",
     "start_time": "2019-11-25T21:13:52.500999Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 arr.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, not only our function is much slower, but it's also (see annotation) a bit too Pythonic. It uses usual Python `float` functions to add new element value to `result`.\n",
    "\n",
    "You should be careful enough using the tools below, but generally it's quite safe to use them with typed memoryviews (but remember, that other objects may also be in scope, those, which do not know about their shape). So, we will skip bounds check. Wow, right?\n",
    "\n",
    "We will also make result a usual C `double`.`@boundscheck(False)` decorator skips all checks, related to whether you're accessing your buffer within bounds. `@wraparound` decorator deactivates negative indexing, as we do not use them and there's no need to check is they are used correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:52.791476Z",
     "start_time": "2019-11-25T21:13:52.777828Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "from cython cimport boundscheck, wraparound\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def sum_arr_c(double[:] a):\n",
    "    \"\"\"Sum elements of `a`.\"\"\"\n",
    "\n",
    "    cdef double result = 0.\n",
    "\n",
    "    # Note, that typed memoryviews know about shape\n",
    "    for i in range(a.shape[0]):\n",
    "        result += a[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, right? Take some time to try to understand C code in annotations and get the idea about the difference between two versions of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:52.853326Z",
     "start_time": "2019-11-25T21:13:52.798688Z"
    }
   },
   "outputs": [],
   "source": [
    "sum_arr(arr_f), sum_arr_c(arr_f), arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:13:53.339928Z",
     "start_time": "2019-11-25T21:13:52.858541Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 sum_arr_c(arr_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that Cython does transformation from C `double` to Python `float` for you:\n",
    "    \n",
    "```c\n",
    "__pyx_t_5 = PyFloat_FromDouble(__pyx_v_result); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 12, __pyx_L1_error)\n",
    "```\n",
    "\n",
    "Note, that one type annotation and two decorators speed up computation by an order of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, do you understand, why results between our function and `np.sum` are slightly different? Think about this for a moment (or Google it!).\n",
    "\n",
    "So, we have a function, which is still slightly worse, than `numpy` equivalent. But we got here without a lot of efforts.\n",
    "\n",
    "As a side note: our summation function can be implemented in `numpy` array specific way (and it  then won't work with standard Python arrays, for example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:03.728477Z",
     "start_time": "2019-11-25T21:14:03.707983Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from cython cimport boundscheck, wraparound\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def sum_arr_np(np.ndarray[np.float64_t, ndim=1] a):\n",
    "    \"\"\"Sum elements of `a`.\"\"\"\n",
    "\n",
    "    cdef double result = 0.\n",
    "    cdef int i\n",
    "\n",
    "    # numpy arrays also know about shape, of course\n",
    "    for i in range(a.shape[0]):\n",
    "        result += a[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:04.255739Z",
     "start_time": "2019-11-25T21:14:03.736968Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 sum_arr_np(arr_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know something about Cython and typed memoryviews, we can go on and try to implement matrix multiplication!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the naive version of matrix multiplication, which just implements general formula for matrix product. Although naive, we'll add some optimizations later to have better memory access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:04.928703Z",
     "start_time": "2019-11-25T21:14:04.912707Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from cython cimport boundscheck, wraparound\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def mat_mult(double[:, :] a, double[:, :] b):\n",
    "    \"\"\"Calculate matrix product.\"\"\"\n",
    "\n",
    "    # Add some code to check dimensions here\n",
    "    # We really need to check dimensions of matrices\n",
    "    # Cause we disabled bounds check\n",
    "    # a.shape[1]==b.shape[0]?\n",
    "        \n",
    "    cdef double[:, :] result = np.zeros((a.shape[0], b.shape[1]))\n",
    "    cdef double accum\n",
    "    cdef int i, j, k\n",
    "    cdef double ak, bk\n",
    "\n",
    "    # Outer loop: rows of a\n",
    "    for i in range(a.shape[0]):\n",
    "        # First inner loop: columns of b\n",
    "        for j in range(b.shape[1]):\n",
    "            accum = 0\n",
    "            # Inner loop: product of row i of a and column j of b\n",
    "            for k in range(a.shape[1]):\n",
    "                accum += a[i, k]*b[k, j]\n",
    "            result[i, j] = accum\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function is quite C-ish. But is it fast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:04.971450Z",
     "start_time": "2019-11-25T21:14:04.931216Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(300, 500)\n",
    "b = np.random.randn(500, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:05.329775Z",
     "start_time": "2019-11-25T21:14:04.976886Z"
    }
   },
   "outputs": [],
   "source": [
    "np.allclose(mat_mult(a, b), np.dot(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:13.197107Z",
     "start_time": "2019-11-25T21:14:05.335676Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 mat_mult(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:13.607721Z",
     "start_time": "2019-11-25T21:14:13.199942Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that fast, right? Why our function is so slow? Let's perform an experiment. We will change the way `b` is stored, so that indexing order for `b` is efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:13.623361Z",
     "start_time": "2019-11-25T21:14:13.612974Z"
    }
   },
   "outputs": [],
   "source": [
    "b_t = np.asfortranarray(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:18.012911Z",
     "start_time": "2019-11-25T21:14:13.629446Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 mat_mult(a, b_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing should be somewhat smaller now. By default, arrays are stored in C-order (row-major), so that stride for last array dimension is the smallest. If we change that to F-order, we suddenly make memory access for `b` much more efficient. Add this to our function, so that we do not need to do it manually, but first let's check how expensive the operation is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 np.asfortranarray(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:27.663891Z",
     "start_time": "2019-11-25T21:14:18.015993Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from cython cimport boundscheck, wraparound\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def mat_mult_t(double[:, ::1] a, double[:, ::1] b):\n",
    "    \"\"\"Calculate matrix product.\"\"\"\n",
    "\n",
    "    # Add some code to check dimensions here\n",
    "    # We really need to check dimensions of matrices\n",
    "    # Cause we disabled bounds check\n",
    "    # a.shape[1]==b.shape[0]?\n",
    "\n",
    "    cdef double[::1, :] b_t = np.asfortranarray(b)\n",
    "        \n",
    "    cdef double[:, :] result = np.zeros((a.shape[0], b.shape[1]))\n",
    "    cdef double accum, ak, bk\n",
    "    cdef int i, j, k\n",
    "\n",
    "    # Outer loop: rows of a\n",
    "    for i in range(a.shape[0]):\n",
    "        # First inner loop: columns of b\n",
    "        for j in range(b_t.shape[1]):\n",
    "            accum = 0\n",
    "            # Inner loop: product of row i of a and column j of b\n",
    "            for k in range(a.shape[1]):\n",
    "                accum += a[i, k]*b_t[k, j]\n",
    "            result[i, j] = accum\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:32.391671Z",
     "start_time": "2019-11-25T21:14:27.666873Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 mat_mult_t(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:14:32.590713Z",
     "start_time": "2019-11-25T21:14:32.394255Z"
    }
   },
   "outputs": [],
   "source": [
    "np.allclose(mat_mult_t(a, b), np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate, how running time depends on matrix shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:16:17.415004Z",
     "start_time": "2019-11-25T21:16:17.405795Z"
    }
   },
   "outputs": [],
   "source": [
    "# New cool package here: now we have nice progress bars\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:20:15.695443Z",
     "start_time": "2019-11-25T21:16:17.418129Z"
    }
   },
   "outputs": [],
   "source": [
    "timings = []\n",
    "\n",
    "for i in tqdm(range(32, 576, 64)):\n",
    "    c = np.random.randn(i, i)\n",
    "    t_np = %timeit -n 10 -r 3 -o -q np.dot(c, c)\n",
    "    t_cy = %timeit -n 10 -r 3 -o -q mat_mult_t(c, c)\n",
    "    timings.append([i, t_np.average, t_cy.average])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:20:16.926978Z",
     "start_time": "2019-11-25T21:20:15.699052Z"
    }
   },
   "outputs": [],
   "source": [
    "timings = np.array(timings)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(timings[:, 0], timings[:, 1], label='numpy')\n",
    "plt.plot(timings[:, 0], timings[:, 2], label='naive')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('matrix size')\n",
    "plt.ylabel('running time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our function is two orders of magnitude slower compared to NumPy `np.dot`. This, however, is expected, as we are using the most straightforward and simple approach.\n",
    "\n",
    "On the next step we may try to implement [tiled matrix multiplication](https://penny-xu.github.io/blog/tiled-matrix-multiplication). But is it worth it? I'll provide an implementation, so that you can try, but generally our access pattern is already good enough for cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermezzo on `range` in `for` loops\n",
    "\n",
    "Cython is smart enough to smash Python `for` loops into plain C `for` loops. This allows for eliminating `StopIteration` exception on each iteration, thus, speeding things up a lot. However, Cython is only able to do this with `range(start, stop)`, while for `range(start, stop, step)` it needs to know the sign of `step`. If there's no way to determine the sign (at compile time!), Cython will default to Python-native loop.\n",
    "\n",
    "Let's compare two implementations of array summation routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from cython cimport boundscheck, wraparound\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def sum_arr(np.ndarray[np.float64_t, ndim=1] a):\n",
    "    \"\"\"Sum elements of `a`.\"\"\"\n",
    "\n",
    "    cdef double result = 0.\n",
    "    cdef int i\n",
    "\n",
    "    # numpy arrays also know about shape, of course\n",
    "    for i in range(a.shape[0]):\n",
    "        result += a[i]\n",
    "    return result\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def sum_arr_step(np.ndarray[np.float64_t, ndim=1] a, int step):\n",
    "    \"\"\"Sum elements of `a`.\"\"\"\n",
    "\n",
    "    cdef double result = 0.\n",
    "    cdef int i\n",
    "\n",
    "    # numpy arrays also know about shape, of course\n",
    "    for i in range(0, a.shape[0], step):\n",
    "        result += a[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `for` loop in `sum_arr` is ok, while very similar loop in `sum_arr_step` is highlighted with yellow (press `+` to see how Python `for` loop looks like compared to simple C-style loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_arr = np.random.randn(50000)\n",
    "step_arr = np.random.randn(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 sum_arr(plain_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 sum_arr_step(step_arr, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `sum_arr_step` is 8 times (!) slower, although it performs the same number of calculations. This can be mitigated by helping Cython to generate efficient code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from cython cimport boundscheck, wraparound\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def sum_arr_step_opt(np.ndarray[np.float64_t, ndim=1] a, int step):\n",
    "    \"\"\"Sum elements of `a`.\"\"\"\n",
    "\n",
    "    cdef double result = 0.\n",
    "    cdef int i, idx\n",
    "    cdef int num_steps = a.shape[0] // step + int(a.shape[0] % step != 0)\n",
    "\n",
    "    # numpy arrays also know about shape, of course\n",
    "    for i in range(num_steps):\n",
    "        idx = i * step\n",
    "        result += a[idx]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_arr_step_opt(step_arr, 7), step_arr[::7].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 step_arr[::4].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 3 sum_arr_step_opt(step_arr, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is now comparable (and you now understand how punitive to performance are Python loops)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiled matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cython: profile=True\n",
    "# cython: linetrace=True\n",
    "# cython: binding=True\n",
    "# distutils: define_macros=CYTHON_TRACE_NOGIL=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:20:16.951803Z",
     "start_time": "2019-11-25T21:20:16.930817Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from cython cimport boundscheck, wraparound\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def mat_mult_tiled(double[:, ::1] a, double[:, ::1] b,\n",
    "                   size_t tile_t):\n",
    "    \"\"\"Calculate matrix product.\"\"\"\n",
    "\n",
    "    # Add some code to check dimensions here\n",
    "    # We really need to check dimensions of matrices\n",
    "    # Cause we disabled bounds check\n",
    "    # a.shape[1]==b.shape[0]?\n",
    "\n",
    "\n",
    "    cdef double[::1, :] b_t = np.asfortranarray(b)\n",
    "\n",
    "    cdef double[:, :] result = np.zeros((a.shape[0], b.shape[1]))\n",
    "    cdef double accum, ak, bk\n",
    "    cdef int ait, ajt, at_dim_0, at_dim_1, ai, aidx, ajdx, bidx\n",
    "    cdef int bit, bjt, bt_dim_0, bt_dim_1, bj, k, kdim\n",
    "    cdef int num_tiles_a0 = a.shape[0] // tile_t + int(a.shape[0] % tile_t != 0)\n",
    "    cdef int num_tiles_a1 = a.shape[1] // tile_t + int(a.shape[1] % tile_t != 0)\n",
    "    cdef int num_tiles_b = b.shape[1] // tile_t + int(b.shape[1] % tile_t != 0)\n",
    "\n",
    "    # Outer loop: row tile of a\n",
    "    for aidx in range(num_tiles_a0):\n",
    "        ait = aidx * tile_t\n",
    "        at_dim_0 = min(tile_t,  a.shape[0] - ait)\n",
    "\n",
    "        # First inner loop: column tile of b\n",
    "        for bidx in range(num_tiles_b):\n",
    "            bjt = bidx * tile_t\n",
    "            bt_dim_1 = min(tile_t,  b.shape[1] - bjt)\n",
    "            \n",
    "            # Second inner loop: column tile of a\n",
    "            for ajdx in range(num_tiles_a1):\n",
    "                ajt = ajdx * tile_t\n",
    "                at_dim_1 = min(tile_t,  a.shape[1] - ajt)\n",
    "                \n",
    "                # Tile matrix multiplication\n",
    "                for ai in range(ait, ait+at_dim_0):\n",
    "                    for bj in range(bjt, bjt+bt_dim_1):\n",
    "                        accum = 0\n",
    "                        for k in range(at_dim_1):\n",
    "                            accum += a[ai, ajt+k]*b_t[ajt+k, bj]\n",
    "                        result[ai, bj] += accum\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:20:18.408001Z",
     "start_time": "2019-11-25T21:20:16.955447Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 3 -r 3 mat_mult_tiled(a, b, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(mat_mult_tiled(a, b, 128), np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider different tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:28:09.186369Z",
     "start_time": "2019-11-25T21:22:26.465918Z"
    }
   },
   "outputs": [],
   "source": [
    "tile_timings = []\n",
    "\n",
    "for i in tqdm(range(16, 256, 16)):\n",
    "    c = np.random.randn(512, 512)\n",
    "    t_cy = %timeit -n 10 -r 3 -o -q mat_mult_tiled(c, c, i)\n",
    "    tile_timings.append([i, t_cy.average])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:28:09.880822Z",
     "start_time": "2019-11-25T21:28:09.189814Z"
    }
   },
   "outputs": [],
   "source": [
    "tile_timings = np.array(tile_timings)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(tile_timings[:, 0], tile_timings[:, 1], label='tiled Cython')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('tile size')\n",
    "plt.ylabel('running time');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_timings = []\n",
    "\n",
    "for i in tqdm(range(32, 576, 64)):\n",
    "    c = np.random.randn(i, i)\n",
    "    t_cy_tiled = %timeit -n 10 -r 3 -o -q mat_mult_tiled(c, c, 32)\n",
    "    tile_timings.append([i, t_cy_tiled.average])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_timings = np.array(tile_timings)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(timings[:, 0], timings[:, 1], \"-o\", label='numpy')\n",
    "plt.plot(timings[:, 0], timings[:, 2], \"-*\", label='naive')\n",
    "plt.plot(tile_timings[:, 0], tile_timings[:, 1], \"-x\", label='tiled')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('matrix size')\n",
    "plt.ylabel('running time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there was no need to add tiling for matrices of size we use. However, tiling is extremely important for matrix multiplication on GPU, as it allows for efficient use of hardware by leveraging shared memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, let's create Numba version to see, what we can get for free. Numba is a JIT compiler for Python. In its basic form it allows to add a JIT decorator to any function, and that function will be JIT-compiled. However, Numba works great with NumPy, but cannot optimize Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:28:10.424241Z",
     "start_time": "2019-11-25T21:28:09.895176Z"
    }
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit, prange\n",
    "\n",
    "@jit(parallel=True)\n",
    "def mat_mult_numba(a, b):\n",
    "    \"\"\"Sum elements of `a`.\"\"\"\n",
    "\n",
    "    # Add some code to check dimensions here\n",
    "    # We really need to check dimensions of matrices\n",
    "    # Cause we disabled bounds check\n",
    "    # a.shape[1]==b.shape[0]?\n",
    "        \n",
    "    result = np.zeros((a.shape[0], b.shape[1]))\n",
    "\n",
    "    # b_t code here\n",
    "\n",
    "    # Outer loop: rows of a\n",
    "    for i in prange(a.shape[0]):\n",
    "        # First inner loop: columns of b\n",
    "        for j in range(b.shape[1]):\n",
    "            accum = 0\n",
    "            # Inner loop: product of row i of a and column j of b\n",
    "            for k in range(a.shape[1]):\n",
    "                ak = a[i, k]\n",
    "                bk = b[k, j]\n",
    "                accum += ak*bk\n",
    "            result[i, j] = accum\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:28:10.726632Z",
     "start_time": "2019-11-25T21:28:10.427183Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:28:14.950033Z",
     "start_time": "2019-11-25T21:28:10.730812Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 mat_mult_t(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:28:15.177298Z",
     "start_time": "2019-11-25T21:28:14.952607Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 mat_mult_tiled(a, b, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T21:28:24.895650Z",
     "start_time": "2019-11-25T21:28:23.430825Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 mat_mult_numba(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On instructor's machine (6-core) the results are the following:\n",
    "\n",
    "- `np.dot`: **~3ms**,\n",
    "- naive Cython implementation with `b` in F-order layout: **~120ms**,\n",
    "- tiled Cython implementation with `b` in F-order layout: **~110ms**,\n",
    "- parallel Numba implementation: **~15ms**.\n",
    "\n",
    "Although it's hard to beat NumPy, we were close enough with very simple implementation. For custom algorithms Cython may be indispensable, and even more so - for wrapping available C libraries, as it allows linking to them. This is possible, because Cython generates C code, and everything (or, better to say, almost everything), which is possible to use in any C code, is available in Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
