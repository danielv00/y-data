{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Exam contains 6 problems, Most of them are of intermediate complexity and follow the material from class or graded assignments. Note, that no loops are allowed in this exam, and all the solutions containing loops will be graded as 0.\n",
    "\n",
    "For this exam you'll need [Titanic](https://www.kaggle.com/c/titanic) and [road accidents](https://www.kaggle.com/daveianhickey/2000-16-traffic-flow-england-scotland-wales) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:28:34.603776Z",
     "start_time": "2019-12-10T04:28:34.062840Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:28:34.729399Z",
     "start_time": "2019-12-10T04:28:34.722007Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T22:01:27.110972Z",
     "start_time": "2019-12-10T22:01:25.282584Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:28:36.261270Z",
     "start_time": "2019-12-10T04:28:36.254114Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "STUDENT = \"Daniel Volchegursky\"\n",
    "ASSIGNMENT = \"exam\"\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:28:37.343105Z",
     "start_time": "2019-12-10T04:28:37.339954Z"
    }
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    import solutions\n",
    "    total_grade = 0\n",
    "    MAX_POINTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Filtering array (2 points).\n",
    "\n",
    "Clip array values according to the following:\n",
    "\n",
    "- given a two-dimensional array `arr` and threshold value `max_val`,\n",
    "- find those rows, for which row values sum is `> max_val`,\n",
    "- and replace largest value for each of those rows with `v` $\\rightarrow$ `v - <row sum> + max_val`.\n",
    "\n",
    "For example, consider the following array and threshold `max_val=8`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:28:38.747272Z",
     "start_time": "2019-12-10T04:28:38.739686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  4],\n",
       "       [-3,  2,  8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 5, 4], [-3, 2, 8]])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row sums are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:28:39.659598Z",
     "start_time": "2019-12-10T04:28:39.654998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since row sum for row `0` is `> max_val`, largest value in that row (`a[0, 1]`, which is `5`), must be replaced with: `5 - 10 + 8 = 3`, resulting in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:28:41.424938Z",
     "start_time": "2019-12-10T04:28:41.419800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  4],\n",
       "       [-3,  2,  8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_clipped = np.array([[1, 3, 4], [-3, 2, 8]])\n",
    "a_clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:08:49.435119Z",
     "start_time": "2019-12-10T01:08:49.429350Z"
    }
   },
   "source": [
    "#### Notes:\n",
    "\n",
    "- **do not change original array**,\n",
    "- in this problem you may need to use **boolean and fancy indexing**, as well as `arr.argmax(...)`,\n",
    "- you **cannot use loops**,\n",
    "- input array is of **any two-dimensional shape** (including `(N,1)` and `(1,N)`), filled with **random integers**,\n",
    "- there may be no rows, which satisfy threshold condition, and in that case resulting array must be identical to input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:36:11.472242Z",
     "start_time": "2019-12-10T04:36:11.468521Z"
    }
   },
   "outputs": [],
   "source": [
    "def clip_array(arr, max_val):\n",
    "    \"\"\"Clip array based on `max_val`.\"\"\"\n",
    "    result=arr.copy()\n",
    "    mask=arr.sum(axis=1) > max_val\n",
    "    indices=arr.argmax(axis=1)\n",
    "    masked_indices=indices[mask]\n",
    "    print('masked_indices=',masked_indices)\n",
    "    print('result[mask,masked_indices]=',result[mask,masked_indices])\n",
    "    print('result.sum(axis=1)-max_val=',result.sum(axis=1)-max_val)\n",
    "    result[mask,masked_indices]-= result.sum(axis=1)[mask]-max_val\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_ID = 1\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, clip_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked_indices= [2]\n",
      "result[mask,masked_indices]= [6]\n",
      "result.sum(axis=1)-max_val= [ 3 -2]\n",
      "result1 = [[ 1  5  3]\n",
      " [-3  2  8]]\n",
      "masked_indices= []\n",
      "result[mask,masked_indices]= []\n",
      "result.sum(axis=1)-max_val= [ -8 -13]\n",
      "result2 = [[ 1  5  6]\n",
      " [-3  2  8]]\n",
      "masked_indices= [2 2]\n",
      "result[mask,masked_indices]= [6 8]\n",
      "result.sum(axis=1)-max_val= [8 3]\n",
      "result3 = [[ 1  5 -2]\n",
      " [-3  2  5]]\n",
      "masked_indices= []\n",
      "result[mask,masked_indices]= []\n",
      "result.sum(axis=1)-max_val= [-3 -2 -1]\n",
      "result4 = [[1]\n",
      " [2]\n",
      " [3]]\n",
      "masked_indices= [2]\n",
      "result[mask,masked_indices]= [3]\n",
      "result.sum(axis=1)-max_val= [2]\n",
      "result5 = [[1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    a1 = np.array([[1, 5, 6], [-3, 2, 8]])\n",
    "    threshold1 = 9\n",
    "    result1 = clip_array(a1, threshold1)\n",
    "    print('result1 =', result1)\n",
    "    a2 = np.array([[1, 5, 6], [-3, 2, 8]])\n",
    "    threshold2 = 20\n",
    "    result2 = clip_array(a2, threshold2)\n",
    "    print('result2 =', result2)\n",
    "    a3 = np.array([[1, 5, 6], [-3, 2, 8]])\n",
    "    threshold3 = 4\n",
    "    result3 = clip_array(a3, threshold3)\n",
    "    print('result3 =', result3)\n",
    "    a4 = np.array([[1, 2, 3]]).T\n",
    "    threshold4 = 4\n",
    "    result4 = clip_array(a4, threshold4)\n",
    "    print('result4 =', result4)\n",
    "    a5 = np.array([[1, 2, 3]])\n",
    "    threshold5 = 4\n",
    "    result5 = clip_array(a5, threshold5)\n",
    "    print('result5 =', result5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate area (1 point).\n",
    "\n",
    "In this problem you will construct a naive Monte-Carlo simulator. Provided with a 2D bounding box, you must calculate it's area:\n",
    "\n",
    "- a bounding box is specified by maximum and minimum `x` and `y`, i.e. a bounding box is a **rectangle** between `minx` and `maxx` over `x`-axis and between `miny` and `maxy` over `y`-axis,\n",
    "- all of `minx`, `maxx`, `miny`, `maxy` are `>=0` and `<=1`,\n",
    "- you can sample **at most** `n_samples` points on 2D place,\n",
    "- ratio of number of points inside a bounding box to total number of points is an **estimate of bounding box area**,\n",
    "- estimate is considered valid, if it's **no more than 10% off of actual area value**,\n",
    "- `n_samples` is chosen in such a way, that **10% error is achievable nearly always**, i.e. chances of getting more then 10% error with correct computation are negligibly small.\n",
    "\n",
    "For example, a bounding box is `minx=0.25`, `maxx=0.5`, `miny=0.1`, `maxy=0.6`. Actual area is `0.125`. Suppose, that we sample `10000` points in unit square $x \\in [0, 1],\\,y \\in [0, 1]$ and 1215 of them are inside the bounding box. Then, an estimate for the bounding box area is `0.1215` (with error of about 2.8%). Image below illustrates this example.\n",
    "\n",
    "![Monte-Carlo integration example](mc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:37:16.154223Z",
     "start_time": "2019-12-10T02:37:16.144904Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_area(minx, maxx, miny, maxy, n_samples):\n",
    "    \"\"\"Calculate area of bounding box.\"\"\"\n",
    "    pts = np.random.random_sample((n_samples,2))\n",
    "    filtered = pts[(pts[:,0] >= minx) & (pts[:,1] >= miny) & (pts[:,0] <= maxx) & (pts[:,1] <= maxy)]\n",
    "    estimate = len(filtered)/n_samples\n",
    "    return estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area =  0.12434\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    samples=50000\n",
    "    area = calc_area(0.25, 0.5, 0.1, 0.6, samples)\n",
    "    print('area = ', area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:25:50.106449Z",
     "start_time": "2019-11-13T23:25:50.095086Z"
    }
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 2\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, calc_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find outliers (3 points).\n",
    "\n",
    "Given an array of shape `(N,2)`, filter all the rows, which are more than `thr` away from other rows. Distance metrics is Euclidean, i.e. distance between rows `i` and `j` is (in pseudocode):\n",
    "\n",
    "```\n",
    "distance(i, j) = sqrt(square(arr[i, 0] - arr[j, 0]) + square(arr[i, 1] - arr[j, 1]))\n",
    "```\n",
    "\n",
    "Distance of row `i` from other rows is:\n",
    "\n",
    "```\n",
    "distance(i) = mean(distance(i, j)), j!=i\n",
    "```\n",
    "\n",
    "Rows, which have `distance(i) > thr` must be filtered. In this problem you **cannot use loops**. Instead, use broadcasting (recall recurrence matrix problem in GA-2 and extend it to two-dimensional case).\n",
    "\n",
    "As an example, consider 1000 samples from standard normal distribution for `x` (axis 1) and `y` (axis 0) and threshold of 2:\n",
    "\n",
    "![Outliers filtering](outliers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:31:55.071291Z",
     "start_time": "2019-12-09T15:31:55.066198Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_outliers(arr, thr):\n",
    "    \"\"\"Find outliers.\"\"\"\n",
    "    aux = arr.reshape(np.prod(arr.shape[:-1]),1,arr.shape[-1])\n",
    "    diff =  arr - aux\n",
    "    distance_matrix = np.sqrt(np.einsum('ijk,ijk->ij', diff, diff)).squeeze()\n",
    "    distance_matrix[distance_matrix == 0] = np.nan\n",
    "    avg = np.nanmean(distance_matrix, axis=1)\n",
    "    mask = avg <= thr\n",
    "    result = arr[mask]\n",
    "    if not TEST:\n",
    "        print ('distance_matrix:', *distance_matrix, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_matrix:\n",
      "[       nan 2.82842712 5.65685425]\n",
      "[2.82842712        nan 2.82842712]\n",
      "[5.65685425 2.82842712        nan]\n",
      "result:\n",
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    arr=np.array([[1,2],[3,4],[5,6]])\n",
    "    threshold=3\n",
    "    result=find_outliers(arr,threshold)\n",
    "    print ('result:', *result, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:00.914340Z",
     "start_time": "2019-12-09T15:32:00.906396Z"
    }
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 3\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, find_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SImple derivative (1 point).\n",
    "\n",
    "Given some value of `x0`, calculate a derivative of sigmoid function at that point. Input is a single floating point value. Output must also be a single floating point value (not a tensor!) equal to derivative of $\\sigma(x)$ at `x0`.\n",
    "\n",
    "Do not use the exact formula for the derivative, but use PyTorch `.backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:15:11.348224Z",
     "start_time": "2019-11-13T23:15:11.334569Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_sigmoid(x0):\n",
    "    \"\"\"Derivative of sigmoid.\"\"\"\n",
    "    x = torch.autograd.Variable(torch.Tensor([x0]),requires_grad=True)\n",
    "    sigmoid = 1/(1 + (-x).exp())\n",
    "    sigmoid.backward()\n",
    "    return x.grad.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = 0.10499356687068939\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    x0=2.0\n",
    "    result = d_sigmoid(x0)\n",
    "    print(\"result =\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:25:50.106449Z",
     "start_time": "2019-11-13T23:25:50.095086Z"
    }
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 4\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, d_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ratio of males travelling alone per class (1 point).\n",
    "\n",
    "Given the Titanic dataset, calculate ratio of males travelling alove (`SipSp==0` and `Parch==0`) per class. In other words, calculate number of males travelling alone in each class, divided by number of passengers in that class.\n",
    "\n",
    "Input is indexed with `PassengerId` and is a concatenation of train and test sets. Output must be a series, indexed by class, containing the requested ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T08:26:56.688466Z",
     "start_time": "2019-11-25T08:26:56.684610Z"
    }
   },
   "outputs": [],
   "source": [
    "def lone_males(df):\n",
    "    \"\"\"Calculate ratio of males travelling alone per class.\"\"\"\n",
    "    lonely_males=df[(df['Sex']=='male')& (df['Parch'] == 0) & (df['SibSp'] == 0)]\n",
    "    result = lonely_males.groupby('Pclass').size() / df.groupby('Pclass').size()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(result)= <class 'pandas.core.series.Series'>\n",
      "result = Pclass\n",
      "1    0.334365\n",
      "2    0.418773\n",
      "3    0.524683\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    url_test='https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/test.csv'\n",
    "    url_train='https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'\n",
    "    titanic_train = pd.read_csv(url_train, index_col=\"PassengerId\")\n",
    "    titanic_test = pd.read_csv(url_test, index_col=\"PassengerId\")\n",
    "    titanic_test[(titanic_test['Sex']=='male')]\n",
    "    titanic = pd.concat([titanic_train, titanic_test], sort=False)\n",
    "    result = lone_males(titanic)\n",
    "    print('type(result)=',type(result))\n",
    "    print('result =', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     url_test='https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/test.csv'\n",
    "#     url_train='https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'\n",
    "#     titanic_train = pd.read_csv(url_train, index_col=\"PassengerId\")\n",
    "#     titanic_test = pd.read_csv(url_test, index_col=\"PassengerId\")\n",
    "#     titanic = pd.concat([titanic_train, titanic_test], sort=False)\n",
    "#     lonely_males=titanic[(titanic['Sex']=='male')& (titanic['Parch'] == 0) & (titanic['SibSp'] == 0)]\n",
    "#     lonely_males.groupby('Pclass').size()/titanic.groupby('Pclass').size()\n",
    "#     titanic.groupby('Pclass').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T08:27:11.838257Z",
     "start_time": "2019-11-25T08:27:11.720830Z"
    }
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 5\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, lone_males)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Worst days on UK roads in 2005 (2 points).\n",
    "\n",
    "Calculate Top-5 days with the largest number of severe accidents (`Accident_Severity < 3`).\n",
    "\n",
    "Input is a **dataframe**, containing all the accidents in 2005 and the following columns: `date_time` (constructed in the same way, as in optional time series notebook) and `Accident_Severity`. Index is a default integer index. Result must be a list (or tuple) of dates (as a `pd.Timestamp`) with 5 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T03:08:04.058718Z",
     "start_time": "2019-12-10T03:08:04.055676Z"
    }
   },
   "outputs": [],
   "source": [
    "def worst_days(df):\n",
    "    \"\"\"Calculate Top 5 most severe days.\"\"\"\n",
    "    df.set_index('date_time', inplace=True)\n",
    "    result = df[(df['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index.values\n",
    "    result = [(pd.Timestamp(x)) for x in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    %pylab inline\n",
    "    plt.style.use('bmh')\n",
    "    import pathlib\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:\n",
      "2005-05-14 00:00:00\n",
      "2005-06-18 00:00:00\n",
      "2005-09-16 00:00:00\n",
      "2005-11-04 00:00:00\n",
      "2005-12-23 00:00:00\n",
      "[Timestamp('2005-05-14 00:00:00'), Timestamp('2005-06-18 00:00:00'), Timestamp('2005-09-16 00:00:00'), Timestamp('2005-11-04 00:00:00'), Timestamp('2005-12-23 00:00:00')]\n",
      "type(result)= <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    DATA_DIR = pathlib.Path(\"./\")\n",
    "#     d = pd.read_csv(DATA_DIR.joinpath('accidents_2005_to_2007.csv.zip'),low_memory=False)\n",
    "#     d.info(memory_usage=\"deep\")\n",
    "#     d.loc[:, 'dt'] = d.Date.str.cat(d.Time, sep=' ', na_rep='00:00')\n",
    "#     d.loc[:, 'date_time'] = pd.to_datetime(d.dt, dayfirst=True)\n",
    "#     d.set_index('date_time', inplace=True)\n",
    "#     d.loc[\"2005\"].to_csv(DATA_DIR.joinpath(\"exam_accidents_2005.csv\"))\n",
    "    accidents_2005 = pd.read_csv(DATA_DIR.joinpath(\"exam_accidents_2005.csv\"), parse_dates=[\"date_time\"])\n",
    "    result = worst_days(accidents_2005)\n",
    "    print ('result:', *result, sep='\\n')\n",
    "    print (result)\n",
    "    print('type(result)=',type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents_2005['date_time'] = accidents_2005['date_time'].apply(lambda x: pd.Timestamp(x))\n",
    "# accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size()\n",
    "# accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index\n",
    "# accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index.values\n",
    "# tuple(accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index.values)\n",
    "# tuple(accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5)[date_time])\n",
    "# accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index.values.tolist()\n",
    "# accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).apply(lambda x: pd.Timestamp(x))\n",
    "# pd.Timestamp(tuple(accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index.values)[0])\n",
    "# accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index.values.apply(lambda x: pd.Timestamp(x))\n",
    "# pd.Series(accidents_2005[(accidents_2005['Accident_Severity']<3)].resample('D').size().sort_values(ascending=False).head(5).index.values).apply(lambda x: pd.Timestamp(x))\n",
    "# accidents_2005 = pd.read_csv(DATA_DIR.joinpath(\"exam_accidents_2005.csv\"), parse_dates=[\"date_time\"])\n",
    "# accidents_2005['date_time'] = accidents_2005['date_time'].apply(lambda x: pd.Timestamp(x))\n",
    "# res = [(pd.Timestamp(x)) for x in t]\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T08:27:11.838257Z",
     "start_time": "2019-11-25T08:27:11.720830Z"
    }
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 6\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, worst_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    print(f\"{STUDENT}: {int(100 * total_grade / MAX_POINTS)}\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
